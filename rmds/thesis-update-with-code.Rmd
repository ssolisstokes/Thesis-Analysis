---
title: "2025 Gila Monster Occupancy Analysis"
author: "Sienna Solis-Stokes"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme:
      success: "#d9534f"
      base_font: 
        google: "Lora"
      heading_font: 
        google: "Lora"
      bootswatch: sandstone
      bslib: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	fig.height = 4,
	fig.width = 7,
	message = FALSE,
	warning = FALSE)

```

This document serves as a chronology of the analysis I've completed to date for the 2025 Gila monster occupancy project. This version of the document shows all code used in analysis. 

# Summary Tables

This section contains summary tables relating to the survey design and effort (transect lengths and survey hours).

```{r summary libraries}
library(dplyr)
library(tidyr)
library(readr)
library(janitor)
library(lubridate)
library(hms)
```
## Transect Distance

To quantify spatial sampling effort and ensure consistency across transects, I calculated transect lengths using UTM coordinates from collection points along each transect. Tables report both total path length and straight-line distance from start to end. The “curviness” ratio expresses the difference between the actual walked path and the straight-line distance. Transect lengths are also summarized by site to evaluate even spatial sampling effort across the study area. 

```{r transect length}
dat <- read_csv("data/data_gmocc_all-ut.csv") %>%
  clean_names()

# exclude detection points from line path
dat <- dat %>%
  filter(!is.na(col_point), col_point != 6) 

# calculate transect length
transect_dist <- dat %>%
  arrange(site_id, tran_id, col_point) %>%                                        # order rows
  group_by(site_id, tran_id) %>%                                                                
  filter(n() >= 2) %>%                                                            # exclude off-transect detections 
  mutate(
    dx = utm_x - lag(utm_x),               # calculating the difference in X from the previous point
    dy = utm_y - lag(utm_y),               # calculating the difference in Y from the previous point
    seg_m = sqrt(dx^2 + dy^2)) %>%         # calculating the pythagorean distance for the line segment between points
  summarise(
    n_points = n(),
    n_segments = sum(!is.na(seg_m)),
    path_m = sum(seg_m, na.rm = TRUE),                                       # sum of all segment lengths (actual path)
    straight_m = sqrt((last(utm_x) - first(utm_x))^2 +
                        (last(utm_y) - first(utm_y))^2),                         # start to end straight line
    curve  = ifelse(straight_m > 0, path_m / straight_m, NA_real_),              # how curvy the path is; curviness ratio; path/straight
    .groups = "drop") %>%          
  mutate(path_km = path_m / 1000,                                                     # m to km convert
    straight_km = straight_m / 1000)

transect_dist
```

## Transect Distance by Site
```{r site length summary}
by_site_summary <- transect_dist %>%
  group_by(site_id) %>%
  summarise(
    n_transects = n(),
    avg_path_km = mean(path_km, na.rm = TRUE),
    total_path_km = sum(path_km, na.rm = TRUE),
    median_path_km = median(path_km, na.rm = TRUE),
    .groups = "drop") %>%
  arrange(desc(total_path_km))                            

by_site_summary
```


## Overall Transect Distance
```{r transect length summary}
overall_summary <- transect_dist %>%
  summarise(
    n_transects = n(),
    avg_path_km = mean(path_km, na.rm = TRUE),
    total_path_km = round(sum(path_km, na.rm = TRUE), 0),
    median_path_km = median(path_km, na.rm = TRUE),
    .groups = "drop")

overall_summary
```

## Survey Effort

To quantify observer sampling effort, I calculated survey duration as the time difference between the start and end collection points for each transect, then multiplied by the number of observers present to estimate total person-hours. Tables show both field time effort (duration of a survey) and labor effort (total person-hours). Effort is summarized by site to evaluate even sampling hours across the study area.

```{r survey effort}
# bring in dataset
data <- read.csv("data/data_gmocc_all-ut.csv")

names(data) <- trimws(names(data))

# select just survey hour data
hours <- data %>%
  select(site_id, tran_id, date, obs_1, obs_2, obs_3, obs_4, time, col_point) %>%
  filter(!grepl("OTD", tran_id, ignore.case = TRUE)) %>%                                    # exclude off-transect times
  filter(col_point %in% c(1, 5))                                                            # only start/end

# make the data wider to prep for the calculations
hours <- hours %>%
  pivot_wider(
    names_from = col_point,
    values_from = time,
    names_prefix = "col_point_") %>%
  rename(start_time = col_point_1,
         end_time = col_point_5)
  
survey_hours <- hours %>%
  mutate(
    start_time = as_hms(parse_date_time(start_time, orders = c("H:M", "H:M:S"))),           # convert to hms 
    end_time = as_hms(parse_date_time(end_time, orders = c("H:M", "H:M:S"))),
    duration_hr = as.numeric(end_time - start_time, units = "hours"),                       # duration in hours
    n_observers = rowSums(!is.na(select(., obs_1:obs_4)) & select(., obs_1:obs_4) != ""),   # count observers
    total_hours = duration_hr * n_observers)                                                # person-hours
```

## Effort by Site
```{r effort by site}
hours_by_site <- survey_hours %>%
  group_by(site_id) %>%
  summarise(
    total_person_hours = round(sum(total_hours, na.rm = TRUE), 0),
    total_effort_hours = round(sum(duration_hr, na.rm = TRUE), 0),
    avg_observers_per_survey = mean(n_observers, na.rm = TRUE),   
    n_surveys = n(),
    .groups = "drop")

hours_by_site
```

## Overall Effort
```{r overall effort summary}
overall_total <- survey_hours %>%
  summarise(
    total_person_hours = round(sum(total_hours, na.rm = TRUE),0),   # adjusted by num observers ; essentially total human labor hours
    total_effort_hours = round(sum(duration_hr, na.rm = TRUE),0))   # actual survey duration ; time in field regardless of how many ppl

overall_total
```

# Raw Data Plots

This section contains density and distribution plots of raw data. Before fitting occupancy models, I evaluated covariate distributions to check for outliers and visualize the data. Density plots were mainly to explore how environmental conditions differed between detection and non-detection points. These plots were exploratory and were not used directly for model selection.

```{r density libraries}
library(dplyr)
library(tidyr)
library(readr)
library(janitor)
library(ggplot2)
```

```{r density set up}
# bring in data set
data_gmocc <- read.csv("data/data_gmocc_all-ut.csv")
names(data_gmocc) <- trimws(names(data_gmocc))

# columns NOT to include in all-vars density facet
no_den <- c("site_id","tran_id","date","col_point","utm_x","utm_y",
            "detection","shr_ne","shr_nw","shr_se","shr_sw",
           "shr_m_area", "pp_mam", "pp_gbird", "pp_rep", "med_vpd", "shr_m_density")

# vars list
density_vars <- data_gmocc %>%
  select(where(is.numeric) &
           !all_of(no_den)) %>%
  names()
```

```{r all site var density plot}
# create a pivot longer table to plot all variables at once
data_gmocc.long <- data_gmocc %>%
  pivot_longer(
    cols = all_of(density_vars),
    names_to = "variable",
    values_to = "value")

# create the plot
ggplot(data_gmocc.long, aes(x = value)) +
  geom_density(fill = "darkorange2", color = "darkorange2", alpha = 0.7) +
  facet_wrap(~ variable, scales = "free", ncol = 3) + 
  labs(title = "Density Plots of All Variables",
       x = "Value", y = "Density") +
  theme_minimal()
```

## Detection vs Non-Detection Distributions
```{r detection vs non-detection density plot}
plot_density_by_det <- function(df, x, xlab, title) {
ggplot(df, aes(x = .data[[x]], fill = factor(detection))) +
  scale_fill_manual(values = c("0" = "grey", "1" = "darkorange2"),
                    labels = c("No Detection","Detection")) +
  geom_density(alpha = 0.5) +
  labs(title = title,
       x = xlab,
       y = "Density",
       fill = "Detection") +
theme_minimal()
}

plot_density_by_det(data_gmocc, "rock_ind", "Rockiness Index","Rockiness by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "air_temp", "Air Temperature (°C)", "Air Temperature by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "gr_temp", "Ground Temperature (°C)", "Ground Temperature by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "avg_wind_spd", "Average Wind Speed", "Average Wind Speed by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "vpd", "Vapor Pressure Deficit (kPa)", "VPD by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "pp_total", "Prey Presence (count)", "Prey Presence by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "elev", "Elevation (m)", "Elevation by Detection Status (All Sites)")
plot_density_by_det(data_gmocc, "shr_pt_density", "Shrub Density (m^2)", "Shrub Density by Detection Status (All Sites)")
```

# Global Occupancy Model

This section contains the global model using spOccupancy::pgOcc. I utilized spOccupancy to fit a single-species Bayesian occupancy model that separates occupancy from detection probability through repeated transect surveys within sites. Models are fit using MCMC and Polya-Gamma data augmentation. 

I cleaned the data prior to running models to exclude off-transect detections and ensure covariates were correctly aligned with the transect replicates. Site-level covariates were used to model occupancy (elevation, shrub density, prey presence, rockiness index), while transect-level covariates were used to model detection (air temperature, ground temperature, vapor pressure deficit, average wind speed, rockiness index). Prior to model fitting, all covariates were z-score standardized.

```{r pgocc-libraries}
library(dplyr)
library(tidyr)
library(spOccupancy)
library(car)
library(tibble)
library(ggplot2)
```

```{r data wrangling}
# bring in master data
gm <- read.csv("data/data_gmocc_all-ut.csv", stringsAsFactors = FALSE)

# remove off transect detections 
gm$tran_id <- trimws(gm$tran_id) # fixing any spacing issues in tran_id
gm <- gm[!grepl("OTD", gm$tran_id, ignore.case = TRUE), ]

# bring in the transect length data
t.length <- read.csv("data/data_gmocc_tran-distance.csv", stringsAsFactors = FALSE)

# remove off transect detections
t.length$tran_id <- trimws(t.length$tran_id)
t.length <- t.length[!grepl("OTD", t.length$tran_id, ignore.case = TRUE), ]

# calculate time since midnight
time <- strsplit(ifelse(is.na(gm$time), "NA:NA:NA", gm$time), ":", fixed = TRUE)
hh <- as.numeric(sapply(time, `[`, 1))
mm <- as.numeric(sapply(time, `[`, 2))
ss <- as.numeric(sapply(time, `[`, 3))
gm$time_sec <- hh*3600 + mm*60 + ss
gm$time_sec[!is.finite(gm$time_sec)] <- NA_real_

# replacement detection covariates
replacement.covs <- c("utm_x", "utm_y", "time", "detection","avg_wind_spd", "air_temp", "rel_hum", "gr_temp", "rock_ind", "shr_nw", "shr_ne", "shr_se", "shr_sw", "shr_pt_density", "vpd", "time_sec")

# function for replacing the detection point to appropriate time/collection point
gm <- gm %>%
  group_by(site_id, tran_id) %>%
  dplyr::group_modify(~ {
    df <- .x
    col.pts <- which(df$col_point %in% 1:5 & !is.na(df$time_sec)) # col_point 1-5
    det.pt <- which(df$col_point == 6 & !is.na(df$time_sec))      # col_point 6 (detection point)
    if (length(col.pts) == 0 || length(det.pt) == 0) return(df)   # if no col_point 1-5 or col_point 6, do nothing ()
    for (i in det.pt) {                                             # for each col_point 6 row, and copy covariates
      dif <- abs(df$time_sec[col.pts] - df$time_sec[i])             # difference in time since midnight
      nearest <- col.pts[which.min(dif)]                            # find nearest in time col_point 1–5        
      df[nearest, replacement.covs] <- df[i, replacement.covs]}
    df}) %>%
  ungroup()

# keep only on-transect collection points 1–5 (remove off-transect detections)
transects <- subset(gm, col_point %in% 1:5)

# add the transect length (path_km)
transects <- merge(transects, t.length[, c("site_id","tran_id","path_km")],
                   by = c("site_id","tran_id"), all.x = TRUE)

# transect-level observation covariates
tran.covs <- transects %>%
  group_by(site_id, tran_id) %>%
  summarise(
    detection = sum(detection, na.rm = TRUE),
    time_sec = mean(time_sec, na.rm = TRUE),
    air_temp = mean(air_temp, na.rm = TRUE),
    gr_temp = mean(gr_temp, na.rm = TRUE),
    wind = mean(avg_wind_spd, na.rm = TRUE),
    vpd = mean(vpd, na.rm = TRUE),
    rockiness = mean(rock_ind, na.rm = TRUE),
    shrub = mean(shr_pt_density, na.rm = TRUE),
    elev = mean(elev, na.rm = TRUE),
    prey = sum(pp_mam,pp_rep, pp_gbird, na.rm = TRUE),
    path_km = mean(path_km, na.rm = TRUE),
    .groups = "drop")

tran.summary <- tran.covs %>%
  group_by(site_id) %>%
  arrange(tran_id, .by_group = TRUE) %>%
  mutate(rep_idx = row_number()) %>%
  ungroup()

all.sites <- sort(unique(tran.summary$site_id))

# max transects at a site
tran.max <- tran.summary %>%
  count(site_id, name = "n_tran") %>%
  summarise(max(n_tran)) %>%
  pull()

# (rows = sites, cols = transect replicates)
# long df
y_long <- expand.grid(
  site_id = all.sites,
  rep_idx = seq_len(tran.max), KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
  left_join(tran.summary %>% 
              select(site_id, rep_idx, detection),
            by = c("site_id","rep_idx")) %>%
  arrange(site_id, rep_idx)

# wide df
y_wide <- y_long %>%
  pivot_wider(names_from = rep_idx, values_from = detection, names_prefix = "rep_") %>%
  arrange(site_id)

y <- as.matrix(y_wide %>% select(starts_with("rep_")))
rownames(y) <- y_wide$site_id

# transect-level summaries (one row per site)
site.covs <- tran.summary %>%
  group_by(site_id) %>%
  summarise(
    rockiness_mean = mean(rockiness, na.rm = TRUE),
    shrub_density_mean = mean(shrub, na.rm = TRUE),
    elevation_mean = mean(elev, na.rm = TRUE),
    prey_total = sum(prey, na.rm = TRUE),
    .groups = "drop") %>%
  arrange(site_id)

# scale site covariates
site.covs$rockiness_z <- as.numeric(scale(site.covs$rockiness_mean))
site.covs$shrubs_z <- as.numeric(scale(site.covs$shrub_density_mean))
site.covs$elev_z <- as.numeric(scale(site.covs$elevation_mean))
site.covs$prey_z <- as.numeric(scale(site.covs$prey_total))

# align rows to y (sites as row names)
site.covs <- site.covs %>% slice(match(rownames(y), site_id))

# start from transect-level covs, pad to max transects per site
det.covs <- expand.grid(
  site_id = all.sites, 
  rep_idx = seq_len(tran.max),
  KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
  left_join(tran.summary %>%
              select(site_id, rep_idx, time_sec, air_temp, gr_temp, wind, vpd, rockiness),
            by = c("site_id","rep_idx")) %>%
  arrange(site_id, rep_idx)

# widen each covariate
time_wide <- det.covs %>% select(site_id, rep_idx, time_sec) %>%
  pivot_wider(names_from = rep_idx, values_from = time_sec, names_prefix = "rep_") %>% arrange(site_id)
a.temp_wide <- det.covs %>% select(site_id, rep_idx, air_temp) %>%
  pivot_wider(names_from = rep_idx, values_from = air_temp, names_prefix = "rep_") %>% arrange(site_id)
gr.temp_wide <- det.covs %>% select(site_id, rep_idx, gr_temp) %>%
  pivot_wider(names_from = rep_idx, values_from = gr_temp, names_prefix = "rep_") %>% arrange(site_id)
wind_wide <- det.covs %>% select(site_id, rep_idx, wind) %>%
  pivot_wider(names_from = rep_idx, values_from = wind, names_prefix = "rep_") %>% arrange(site_id)
vpd_wide <- det.covs %>% select(site_id, rep_idx, vpd) %>%
  pivot_wider(names_from = rep_idx, values_from = vpd, names_prefix = "rep_") %>% arrange(site_id)
rock_wide <- det.covs %>% select(site_id, rep_idx, rockiness) %>%
  pivot_wider(names_from = rep_idx, values_from = rockiness, names_prefix = "rep_") %>% arrange(site_id)

# covariate matricies; alligned to y matrix
time_mat <- as.matrix(time_wide %>% select(starts_with("rep_")))[match(rownames(y), time_wide$site_id), ]
a.temp_mat <- as.matrix(a.temp_wide  %>% select(starts_with("rep_")))[match(rownames(y), a.temp_wide$site_id), ]
gr.temp_mat <- as.matrix(gr.temp_wide   %>% select(starts_with("rep_")))[match(rownames(y), gr.temp_wide$site_id), ]
wind_mat <- as.matrix(wind_wide %>% select(starts_with("rep_")))[match(rownames(y), wind_wide$site_id), ]
vpd_mat <- as.matrix(vpd_wide  %>% select(starts_with("rep_")))[match(rownames(y), vpd_wide$site_id), ]
rock_mat <- as.matrix(rock_wide %>% select(starts_with("rep_")))[match(rownames(y), rock_wide$site_id), ]

# z-score scale each detection matrix; across all cells
time_mat[] <- (time_mat - mean(time_mat, na.rm = TRUE))/sd(time_mat, na.rm = TRUE)
a.temp_mat[] <- (a.temp_mat - mean(a.temp_mat, na.rm = TRUE))/sd(a.temp_mat,  na.rm = TRUE)
gr.temp_mat[] <- (gr.temp_mat - mean(gr.temp_mat, na.rm = TRUE))/sd(gr.temp_mat,   na.rm = TRUE)
wind_mat[] <- (wind_mat - mean(wind_mat, na.rm = TRUE))/sd(wind_mat, na.rm = TRUE)
vpd_mat[] <- (vpd_mat - mean(vpd_mat, na.rm = TRUE))/sd(vpd_mat,  na.rm = TRUE)
rock_mat[] <- (rock_mat - mean(rock_mat, na.rm = TRUE))/sd(rock_mat, na.rm = TRUE)
```

To fit the PGOcc framework, I constructed a site-level occupancy covariate dataframe with one row per site and a detection covariate list containing matrices with dimensions sites × replicates (transects). Detection covariates were summarized at the transect level, reshaped into replicate matrices, and aligned to the detection history matrix.  

```{r prep covariates for pgOcc}
occ.cov_df <- data.frame(
  rockiness = site.covs$rockiness_z,
  shrubs    = site.covs$shrubs_z,
  elev      = site.covs$elev_z,
  prey      = site.covs$prey_z)
rownames(occ.cov_df) <- site.covs$site_id

det.cov_list <- list(
  time = time_mat,
  vpd  = vpd_mat,
  rock = rock_mat,
  t_air = a.temp_mat,
  t_gr  = gr.temp_mat,
  wind  = wind_mat)
```

## MCMC, initial values, priors
```{r set initial values and parameters}
gm.inits <- list(
  alpha = 0, 
  beta  = 0, 
  z = apply(y, 1, max, na.rm = TRUE))

gm.priors <- list(
  alpha.normal = list(mean = 0, var = 2.72), 
  beta.normal  = list(mean = 0, var = 2.72))

n.samples <- 10000
n.burn    <- 5000
n.thin    <- 5
n.chains  <- 3
```

## Global Model Fit (pgOcc)
```{r Global model fit}
global.occ.formula <- ~ rockiness + shrubs + elev + prey
global.det.formula <- ~ rock + I(t_air^2) + t_air + vpd + wind + I(t_gr^2) + t_gr

global_model <- PGOcc(
  occ.formula = global.occ.formula,
  det.formula = global.det.formula, 
  data = list(
    y = y,
    occ.covs = occ.cov_df,
    det.covs = det.cov_list),
  inits = gm.inits, 
  n.samples = n.samples, 
  priors = gm.priors, 
  n.omp.threads = 1, 
  verbose = FALSE,
  n.report = 2000, 
  n.burn = n.burn, 
  n.thin = n.thin, 
  n.chains = n.chains)

summary(global_model)
```

In the global model, all occupancy covariates had 95% credible intervals overlapping zero, indicating significant uncertainty in the magnitude and direction of individual habitat effects on occupancy. This is not unexpected given the small number of sites and low detection frequency (17 detections across 500 transects), and it reinforces the need for model selection and model averaging to better assess habitat–occupancy relationships.

In contrast, detection probability was more strongly influenced covariates. Vapor pressure deficit showed a positive effect on detection (logit scale), indicating increased detectability under drier atmospheric conditions, while wind speed showed a strong negative effect, indicating reduced detectability under windier conditions. Other detection covariates (rockiness index, air temperature, and ground temperature) had credible intervals overlapping zero, indicating weaker support. These effects are biologically plausible for track-based detections: drier, looser sand can improve track visibility and persistence, while wind reduces track persistence and decreases detectability.

Overall, the global model suggests detectability is driven more by short-term/survey level environmental conditions than occupancy is by site-level habitat covariates (in this dataset).

## Diagnostics & Posterior Predictive Checks

This section contains trace plots to evaluate adequate MCMC mixing and convergence, and posterior predictive checks using the Freeman-Tukey statistic and chi-squared test summarized at both the site and transect level.

### MCMC Trace Plots

In these plots we're looking for what is called a "hairy caterpillar". In the lines we hope to see high overlap, and no flat sections or clear trend lines to show that chains are well-mixed. These plots indicate model convergence and adequate model fit. 

```{r MCMC trace plots global}

plot(global_model, "beta", density = FALSE) # occupancy parameters
plot(global_model, "alpha", density = FALSE) # detection parameters
```

### Posterior Predictive Checks

spOccupancy contains the ppcOcc() function, which groups the data by row (site) or by column (replicate) and calculates a fit statistic. ppcOcc() returns posterior samples of the fit statistic for the observed dataset and for replicated datasets generated under the model. The function supports the Freeman–Tukey and chi-squared statistics. A Bayesian p-value near 0.5 indicates adequate fit, while values < 0.1 or > 0.9 suggest lack of fit.

### Freeman-Tukey Test
```{r freeman tukey global}
global.site_tukey <- ppcOcc(global_model, fit.stat = "freeman-tukey", group = 1) # site
global.rep_tukey <- ppcOcc(global_model, fit.stat = "freeman-tukey", group = 2) # replicate

summary(global.site_tukey)
summary(global.rep_tukey)
```

Bayesian p-values for the site and replicate data using the Freeman-Tukey test fall within acceptable ranges indicating no lack of fit, below are visual representations of the fit statistics for the actual and replicate data.

```{r freeman tukey global plot sites}
# visualization 
# create df of group 1 (site); color for actual data set
global.site.ppc_df <- data.frame(fit = global.site_tukey$fit.y, 
                                 fit.rep = global.site_tukey$fit.y.rep, 
                                 color = 'lightskyblue1')
# set color for fit data
global.site.ppc_df$color[global.site.ppc_df$fit.rep > global.site.ppc_df$fit] <- 'lightsalmon'

plot(global.site.ppc_df$fit, global.site.ppc_df$fit.rep, bg = global.site.ppc_df$color, pch = 21, 
     ylab = 'Fit', xlab = 'True') 
lines(global.site.ppc_df$fit, global.site.ppc_df$fit, col = 'black')

# create df of group 2 (replicates); color for actual data set
global.rep.ppc_df <- data.frame(fit = global.rep_tukey$fit.y, 
                                fit.rep = global.rep_tukey$fit.y.rep, 
                                color = 'lightskyblue1')
# set color for fit data
global.rep.ppc_df$color[global.rep.ppc_df$fit.rep > global.rep.ppc_df$fit] <- 'lightsalmon'

plot(global.rep.ppc_df$fit, global.rep.ppc_df$fit.rep, bg = global.rep.ppc_df$color, pch = 21, 
     ylab = 'Fit', xlab = 'True') 
lines(global.rep.ppc_df$fit, global.rep.ppc_df$fit, col = 'black')
```

### Chi-Squared Test 
```{r chi squared test}
global.site_chi <- ppcOcc(global_model, fit.stat = "chi-squared", group = 1) # site
global.rep_chi <- ppcOcc(global_model, fit.stat = "chi-squared", group = 2) # replicate

summary(global.site_chi)
summary(global.rep_chi)
```

Bayesian p-values for the site and replicate data using the Chi-squared test fall within acceptable ranges indicating no lack of fit..

# Collinearity Assessment
To evaluate multicollinearity I examined variance inflation factors (VIFs) and correlation matrices for occupancy and detection covariates separately.

## Occupancy Variables
```{r collinearity-occupancy vars}
round(cor(occ.cov_df, use = "pairwise.complete.obs"), 2)
pairs(occ.cov_df )
round(vif(lm(rep(1, nrow(occ.cov_df)) ~ ., data = occ.cov_df)), 2)
```

Correlation coefficients among occupancy covariates are generally low, with the strongest correlation between shrub density and elevation. Prey presence shows a moderate correlation with elevation and any correlations involving rockiness were low/weak. VIFs are all < 3, which is well under the commonly used threshold for problematic multicollinearity. Overall, although a few covariates show moderate correlation, multicollinearity is unlikely to meaningfully impact model stability, and all occupancy covariates were retained for model selection.

## Detection Variables
```{r collinearity-detection vars}
# convert det_list to df 
det.cov_df <- data.frame(
  rock = as.vector(det.cov_list$rock),
  t_air = as.vector(det.cov_list$t_air),
  t_gr = as.vector(det.cov_list$t_gr),
  vpd = as.vector(det.cov_list$vpd),
  wind = as.vector(det.cov_list$wind))

det.cov_df <- det.cov_df[complete.cases(det.cov_df), ]
round(cor(det.cov_df, use ="pairwise.complete.obs" ), 2)
pairs(det.cov_df)
round(vif(lm(rep(1, nrow(det.cov_df)) ~ ., data = det.cov_df)), 2)
```

Correlation coefficients among detection covariates show a strong correlation among any weather-related variables. Air temperature, ground temperature, and vapor pressure deficit were all highly correlated. In contrast, rockiness and wind showed weak correlation with other detection covariates. VIFs show the same pattern with values very high for air temperature and vapor pressure deficit, and moderately high for ground temperature all exceeding the commonly used threshold. To avoid model instability, detection models did not include multiple highly collinear predictors simultaneously.

# Occupancy Covariate Selection

To start the model-selection process, I constructed occupancy covariate models using candidate occupancy formulas and the global detection formula. I created candidate occupancy covariate formulas representing biological hypotheses for how occupancy varies with habitat structure. Models were compared using WAIC, and model weights (derived from WAIC differences) were used to calculate variable importance and quantify model support. Additionally, I calculated model-averaged coefficients to provide a single weighted estimate of covariate effects across models.

Candidate Model list: </br>
  - om1: ~1 </br>
  - om2: ~ rockiness + shrubs + elev </br>
  - om3: ~ rockiness + shrubs + prey </br>
  - om4: ~ rockiness + shrubs </br>
  - om5: ~ rockiness + prey </br>
  - om6: ~ shrubs + prey </br>
  - om7: ~ rockiness </br>
  - om8: ~ shrubs </br>
  

## Candidate Models
```{r occupancy candidate models}
# occupancy formulas + global detection
om1 <- PGOcc(occ.formula = ~ 1,
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# habitat + elev
om2 <- PGOcc(occ.formula = ~ rockiness + shrubs + elev, 
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000,  
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# habitat + prey
om3 <- PGOcc(occ.formula = ~ rockiness + shrubs + prey, 
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# habitat
om4 <- PGOcc(occ.formula = ~ rockiness + shrubs, 
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# rockiness + prey
om5 <- PGOcc(occ.formula = ~ rockiness + prey,
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# vegetation + prey
om6 <- PGOcc(occ.formula = ~ shrubs + prey,
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# rockiness
om7 <- PGOcc(occ.formula = ~ rockiness,
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

# shrub density
om8 <- PGOcc(occ.formula = ~ shrubs,
             det.formula = global.det.formula, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)
```

## WAIC Table
```{r occupancy waic tbl}
om1.waic <- waicOcc(om1)
om2.waic <- waicOcc(om2)
om3.waic <- waicOcc(om3)
om4.waic <- waicOcc(om4)
om5.waic <- waicOcc(om5)
om6.waic <- waicOcc(om6)
om7.waic <- waicOcc(om7)
om8.waic <- waicOcc(om8)

om1.df <- data.frame(model = "om1", t(om1.waic))
om2.df <- data.frame(model = "om2", t(om2.waic))
om3.df <- data.frame(model = "om3", t(om3.waic))
om4.df <- data.frame(model = "om4", t(om4.waic))
om5.df <- data.frame(model = "om5", t(om5.waic))
om6.df <- data.frame(model = "om6", t(om6.waic))
om7.df <- data.frame(model = "om7", t(om7.waic))
om8.df <- data.frame(model = "om8", t(om8.waic))

om.waic_df <- bind_rows(list(om1.df, om2.df, om3.df, om4.df, om5.df, om6.df, om7.df, om8.df))

om.waic_tbl <- 
  om.waic_df %>%
  mutate(
    elpd = as.numeric(elpd),
    pD = as.numeric(pD),
    WAIC = as.numeric(WAIC)) %>%
  mutate(
    delta = WAIC - min(WAIC),
    weight = exp(-0.5 * delta)/ sum (exp(-0.5 * delta)) # Burnham & Andserson 2002, 2004 model weights formula
  ) %>%  
  arrange(WAIC)


om.waic_tbl
```

Model selection shows most candidate models with delta <2, indicating an overall similar predictive power among models. Model weights are similarly distributed across candidate models, with model om3 exhibiting a slightly higher weight. 


## Variable Importance
```{r occupancy variable importance}
# model weights as objects
om1.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om1"]
om2.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om2"]
om3.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om3"]
om4.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om4"]
om5.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om5"]
om6.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om6"]
om7.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om7"]
om8.weight <- om.waic_tbl$weight[om.waic_tbl$model == "om8"]

# calculate sum weight and variable importance
rockiness.sum_weight <- om2.weight + om3.weight + om4.weight + om5.weight + om7.weight
shrub.sum_weight <- om2.weight + om3.weight + om4.weight + om6.weight + om8.weight
elev.sum_weight <- om2.weight
prey.sum_weight <- om3.weight + om5.weight + om6.weight

om.var.importance <- data.frame(
  variable = c("rockiness","shrub","elev","prey"),
  sum_weight = c(rockiness.sum_weight, shrub.sum_weight, elev.sum_weight, prey.sum_weight))

om.var.importance
```

The most consistently supported predictors of occupancy after calculating summed model weights are shrub density and rockiness. Prey presence shows moderate support while elevation has the weakest support. These results suggest that vegetation structure and substrate characteristics are more important factors when predicting Gila monster site occupancy than elevation or observed adult prey presence in this dataset. 

## Model-Averaged Coefficients
```{r model avg coef occupancy}
om1_samps <- as.matrix(om1$beta.samples)
om2_samps <- as.matrix(om2$beta.samples)
om3_samps <- as.matrix(om3$beta.samples)
om4_samps <- as.matrix(om4$beta.samples)
om5_samps <- as.matrix(om5$beta.samples)
om6_samps <- as.matrix(om6$beta.samples)
om7_samps <- as.matrix(om7$beta.samples)
om8_samps <- as.matrix(om8$beta.samples)

post_mean_or0 <- function(samps, coef_name) {
if (coef_name %in% colnames(samps)) mean(samps[, coef_name], na.rm = TRUE) else 0
}

# intercept
om1_int <- post_mean_or0(om1_samps, "(Intercept)")
om2_int <- post_mean_or0(om2_samps, "(Intercept)")
om3_int <- post_mean_or0(om3_samps, "(Intercept)")
om4_int <- post_mean_or0(om4_samps, "(Intercept)")
om5_int <- post_mean_or0(om5_samps, "(Intercept)")
om6_int <- post_mean_or0(om6_samps, "(Intercept)")
om7_int <- post_mean_or0(om7_samps, "(Intercept)")
om8_int <- post_mean_or0(om8_samps, "(Intercept)")

# rockiness
om1_rockiness <- post_mean_or0(om1_samps, "rockiness")
om2_rockiness <- post_mean_or0(om2_samps, "rockiness")
om3_rockiness <- post_mean_or0(om3_samps, "rockiness")
om4_rockiness <- post_mean_or0(om4_samps, "rockiness")
om5_rockiness <- post_mean_or0(om5_samps, "rockiness")
om6_rockiness <- post_mean_or0(om6_samps, "rockiness")
om7_rockiness <- post_mean_or0(om7_samps, "rockiness")
om8_rockiness <- post_mean_or0(om8_samps, "rockiness")

# shrubs
om1_shrubs <- post_mean_or0(om1_samps, "shrubs")
om2_shrubs <- post_mean_or0(om2_samps, "shrubs")
om3_shrubs <- post_mean_or0(om3_samps, "shrubs")
om4_shrubs <- post_mean_or0(om4_samps, "shrubs")
om5_shrubs <- post_mean_or0(om5_samps, "shrubs")
om6_shrubs <- post_mean_or0(om6_samps, "shrubs")
om7_shrubs <- post_mean_or0(om7_samps, "shrubs")
om8_shrubs <- post_mean_or0(om8_samps, "shrubs")

# elev
om1_elev <- post_mean_or0(om1_samps, "elev")
om2_elev <- post_mean_or0(om2_samps, "elev")
om3_elev <- post_mean_or0(om3_samps, "elev")
om4_elev <- post_mean_or0(om4_samps, "elev")
om5_elev <- post_mean_or0(om5_samps, "elev")
om6_elev <- post_mean_or0(om6_samps, "elev")
om7_elev <- post_mean_or0(om7_samps, "elev")
om8_elev <- post_mean_or0(om8_samps, "elev")

# prey
om1_prey <- post_mean_or0(om1_samps, "prey")
om2_prey <- post_mean_or0(om2_samps, "prey")
om3_prey <- post_mean_or0(om3_samps, "prey")
om4_prey <- post_mean_or0(om4_samps, "prey")
om5_prey <- post_mean_or0(om5_samps, "prey")
om6_prey <- post_mean_or0(om6_samps, "prey")
om7_prey <- post_mean_or0(om7_samps, "prey")
om8_prey <- post_mean_or0(om8_samps, "prey")

# multiply each coefficient by its model’s weight and sum across models
om.avg_int <-
(om1_int * om1.weight) + (om2_int * om2.weight) +
(om3_int * om3.weight) + (om4_int * om4.weight) +
(om5_int * om5.weight) + (om6_int * om6.weight) +
(om7_int * om7.weight) + (om8_int * om8.weight)

om.avg_rockiness <-
(om1_rockiness * om1.weight) + (om2_rockiness * om2.weight) +
(om3_rockiness * om3.weight) + (om4_rockiness * om4.weight) +
(om5_rockiness * om5.weight) + (om6_rockiness * om6.weight) +
(om7_rockiness * om7.weight) + (om8_rockiness * om8.weight)

om.avg_shrubs <-
(om1_shrubs * om1.weight) + (om2_shrubs * om2.weight) +
(om3_shrubs * om3.weight) + (om4_shrubs * om4.weight) +
(om5_shrubs * om5.weight) + (om6_shrubs * om6.weight) +
(om7_shrubs * om7.weight) + (om8_shrubs * om8.weight)

om.avg_elev <-
(om1_elev * om1.weight) + (om2_elev * om2.weight) +
(om3_elev * om3.weight) + (om4_elev * om4.weight) +
(om5_elev * om5.weight) + (om6_elev * om6.weight) +
(om7_elev * om7.weight) + (om8_elev * om8.weight)

om.avg_prey <-
(om1_prey * om1.weight) + (om2_prey * om2.weight) +
(om3_prey * om3.weight) + (om4_prey * om4.weight) +
(om5_prey * om5.weight) + (om6_prey * om6.weight) +
(om7_prey * om7.weight) + (om8_prey * om8.weight)

om.modavg <- data.frame(
term = c("(Intercept)", "rockiness", "shrubs", "elev", "prey"),
avg_coefficients = c(om.avg_int, om.avg_rockiness, om.avg_shrubs, om.avg_elev, om.avg_prey))

om.modavg
```

Model-averaged coefficients suggest that occupancy increases with shrub density and decreases with rockiness index, while elevation and prey presence show weaker effects. Because coefficients were model-averaged, these values reflect both effect magnitude and frequency with which variables appeared in candidate models. This reinforces the importance of habitat structure in predicting Gila monster site occupancy.

## Final Occupancy Formula

Based on WAIC model selection and variable importance results, the final occupancy formula selected is: (~ rockiness + shrubs) for the most parsimonious and biologically meaningful model. Model selection indicates candidate models containing rockiness and shrub density receive the strongest support and variable-importance results show both contribute strongly to explaining Gila monster site occupancy. 

```{r occupancy formula}
fit.occupancy.formula <- ~ rockiness + shrubs
```

# Detection Covariate Selection

After selecting the best-fit occupancy covariate formula, I followed the same workflow as the previous section but for the detection formula. Within this set of candidate models, one model was tested with occupancy set to 1. The goal of this model selection process was to identify the most parsimonious detection formula which improves model fit while avoiding unnecessary model complexity.

Candidate Model list: </br>
  - dm1: ~ 1 </br>
  - dm2: ~ rock  </br>
  - dm3: ~ t_gr + I(t_gr^2) </br>
  - dm4: ~ rock + wind </br>
  - dm5: ~ rock + t_gr + I(t_gr^2) </br>
  - dm6: ~ wind + t_gr + I(t_gr^2) </br>
  - dm7: ~ rock + wind + t_gr + I(t_gr^2) </br>
  
  
## Candidate Models
```{r detection candidate models}
dm1 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ 1, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

dm2 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ rock, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)


dm3 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ t_gr + I(t_gr^2), 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

dm4 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ rock + wind, 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

dm5 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ rock + t_gr + I(t_gr^2),
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

dm6 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ wind + t_gr + I(t_gr^2), 
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)

dm7 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ rock + wind + t_gr + I(t_gr^2),
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits, 
             n.samples = n.samples, 
             priors = gm.priors, 
             n.omp.threads = 1, 
             verbose = FALSE, 
             n.report = 2000, 
             n.burn = n.burn, 
             n.thin = n.thin, 
             n.chains = n.chains)
```

## WAIC Table
```{r detection waic tbl}
dm1.waic <- waicOcc(dm1)
dm2.waic <- waicOcc(dm2)
dm3.waic <- waicOcc(dm3)
dm4.waic <- waicOcc(dm4)
dm5.waic <- waicOcc(dm5)
dm6.waic <- waicOcc(dm6)
dm7.waic <- waicOcc(dm7)

dm1.df <- data.frame(model = "dm1", t(dm1.waic))
dm2.df <- data.frame(model = "dm2", t(dm2.waic))
dm3.df <- data.frame(model = "dm3", t(dm3.waic))
dm4.df <- data.frame(model = "dm4", t(dm4.waic))
dm5.df <- data.frame(model = "dm5", t(dm5.waic))
dm6.df <- data.frame(model = "dm6", t(dm6.waic))
dm7.df <- data.frame(model = "dm7", t(dm7.waic))

dm.waic_df <- bind_rows(list(dm1.df, dm2.df, dm3.df, dm4.df, dm5.df, dm6.df, dm7.df))

dm.waic_tbl <- 
  dm.waic_df %>%
  mutate(
    elpd = as.numeric(elpd),
    pD = as.numeric(pD),
    WAIC = as.numeric(WAIC)) %>%
  mutate(
    delta = WAIC - min(WAIC),
    weight = exp(-0.5 * delta)/ sum (exp(-0.5 * delta))  # Burnham & Anderson 2002, 2004 model weights formula
  ) %>%
  arrange(WAIC)


dm.waic_tbl
```

Detection model selection shows top models with delta <2 containing some combination of wind, rockiness, and ground temperature effects. Models lacking these covariates or including only a single predictor are weaker and contribute minimal model weight.

## Variable Importance
```{r detection variable importance}
# model weights as objects
dm1.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm1"]
dm2.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm2"]
dm3.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm3"]
dm4.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm4"]
dm5.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm5"]
dm6.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm6"]
dm7.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm7"]

rock.sum_weight <- dm2.weight + dm4.weight + dm5.weight + dm7.weight
t_gr.sum_weight <- dm3.weight + dm5.weight + dm6.weight + dm7.weight
wind.sum_weight <- dm4.weight + dm6.weight + dm7.weight

dm.var.importance <- data.frame(
variable = c("rock", "t_gr", "wind"),
sum_weight = c(rock.sum_weight, t_gr.sum_weight, wind.sum_weight))

dm.var.importance
```

Summed model weights indicate wind is the most consistently supported predictor of detection across candidate models. Rockiness shows moderate support, followed by ground temperature with slightly lower support. This suggests that detection probability decreased under windy conditions, most likely due to reduced track persistence and visibility in loose sand. Rockiness also shows significant support, consistent with tracks being easier to detect on sandier substrates that retain Gila monster sign than rockier surfaces.

## Model-Averaged Coefficients
```{r model avg coef detection}
# dm1 posterior means
dm1.mat <- as.matrix(dm1$alpha.samples)
dm1.means <- colMeans(dm1.mat)
dm1_int <- dm1.means["(Intercept)"]
dm1_rock <- 0
dm1_tgr <- 0
dm1_tgr2 <- 0
dm1_wind <- 0

# dm2 posterior means
dm2.mat <- as.matrix(dm2$alpha.samples)
dm2.means <- colMeans(dm2.mat)
dm2_int <- dm2.means["(Intercept)"]
dm2_rock <- dm2.means["rock"]
dm2_tgr <- 0
dm2_tgr2 <- 0
dm2_wind <- 0

# dm3 posterior means
dm3.mat <- as.matrix(dm3$alpha.samples)
dm3.means <- colMeans(dm3.mat)
dm3_int <- dm3.means["(Intercept)"]
dm3_rock <- 0
dm3_tgr <- dm3.means["t_gr"]
dm3_tgr2 <- dm3.means["I(t_gr^2)"]
dm3_wind <- 0

# dm4 posterior means
dm4.mat <- as.matrix(dm4$alpha.samples)
dm4.means <- colMeans(dm4.mat)
dm4_int <- dm4.means["(Intercept)"]
dm4_rock <- dm4.means["rock"]
dm4_tgr <- 0
dm4_tgr2 <- 0
dm4_wind <- dm4.means["wind"]

# dm5 posterior means
dm5.mat <- as.matrix(dm5$alpha.samples)
dm5.means <- colMeans(dm5.mat)
dm5_int <- dm5.means["(Intercept)"]
dm5_rock <- dm5.means["rock"]
dm5_tgr <- dm5.means["t_gr"]
dm5_tgr2 <- dm5.means["I(t_gr^2)"]
dm5_wind <- 0

# dm6 posterior means
dm6.mat <- as.matrix(dm6$alpha.samples)
dm6.means <- colMeans(dm6.mat)
dm6_int <- dm6.means["(Intercept)"]
dm6_rock <- 0
dm6_tgr <- dm6.means["t_gr"]
dm6_tgr2 <- dm6.means["I(t_gr^2)"]
dm6_wind <- dm6.means["wind"]

# dm7 posterior means
dm7.mat <- as.matrix(dm7$alpha.samples)
dm7.means <- colMeans(dm7.mat)
dm7_int <- dm7.means["(Intercept)"]
dm7_rock <- dm7.means["rock"]
dm7_tgr <- dm7.means["t_gr"]
dm7_tgr2 <- dm7.means["I(t_gr^2)"]
dm7_wind <- dm7.means["wind"]

# weighted averages
dm.avg_int <- (dm1_int * dm1.weight) + (dm2_int * dm2.weight) + (dm3_int * dm3.weight) +
(dm4_int * dm4.weight) + (dm5_int * dm5.weight) + (dm6_int * dm6.weight) + (dm7_int * dm7.weight)

dm.avg_rock <- (dm1_rock * dm1.weight) + (dm2_rock * dm2.weight) + (dm3_rock * dm3.weight) +
(dm4_rock * dm4.weight) + (dm5_rock * dm5.weight) + (dm6_rock * dm6.weight) + (dm7_rock * dm7.weight)

dm.avg_tgr <- (dm1_tgr * dm1.weight) + (dm2_tgr * dm2.weight) + (dm3_tgr * dm3.weight) +
(dm4_tgr * dm4.weight) + (dm5_tgr * dm5.weight) + (dm6_tgr * dm6.weight) + (dm7_tgr * dm7.weight)

dm.avg_tgr2 <- (dm1_tgr2 * dm1.weight) + (dm2_tgr2 * dm2.weight) + (dm3_tgr2 * dm3.weight) +
(dm4_tgr2 * dm4.weight) + (dm5_tgr2 * dm5.weight) + (dm6_tgr2 * dm6.weight) + (dm7_tgr2 * dm7.weight)

dm.avg_wind <- (dm1_wind * dm1.weight) + (dm2_wind * dm2.weight) + (dm3_wind * dm3.weight) +
(dm4_wind * dm4.weight) + (dm5_wind * dm5.weight) + (dm6_wind * dm6.weight) + (dm7_wind * dm7.weight)

dm.modavg <- data.frame(
term = c("(Intercept)", "rock", "t_gr", "I(t_gr^2)", "wind"),
avg_coefficients = c(dm.avg_int, dm.avg_rock, dm.avg_tgr, dm.avg_tgr2, dm.avg_wind))

dm.modavg
```


Model-averaged coefficients show that detection probability is primarily influenced by wind (negative effect), rockiness (positive effect), and nonlinear ground temperature effects. Overall this reinforces that environmental conditions and substrate characteristics strongly impact detection probability, and emphasizes the importance of modeling detectability when surveying cryptic species.

## Initial Detection Formula

Based on WAIC model selection and variable importance results, the final detection model formula contains rockiness and wind as detection covariates (~ rock + wind). Results show that substrate type and wind conditions explain the majority of variation in detection probability, and the addition of ground temperature did not provide significant improvement to the model fit.

```{r detection formula}
fit.detection.formula.1 <- ~ rock + wind 
```

# Bootstrap Analysis

As a complementary analysis to analyze detection at a collection point level versus the transect level I used stratified bootstrap resampling to estimate differences in mean covariate values between detection and non-detection observations. Bootstrap confidence intervals and two-sided p-values in this section summarize how consistently each covariate differs between the two groups under resampling. 


```{r bootstrap libraries}
library(dplyr)
library(tidyr)
library(purrr)
library(rsample)
library(broom)
library(tibble)
library(ggplot2)
```

```{r bootstrap set up & resampling}
transects.bs <- transects %>%
mutate(detection = as.logical(detection))

det.covs <- transects.bs %>%
select(detection, rock_ind, air_temp, gr_temp, avg_wind_spd, vpd)

set.seed(456)

boot.resamples <- bootstraps(det.covs, times = 2000, strata = detection) 

# function to run all bootstrap differences between detection/non-detection covariates
covariate.diffs <- function(split) {
df <- analysis(split)

tibble(
rock.diff = mean(df$rock_ind[df$detection], na.rm = TRUE) - mean(df$rock_ind[!df$detection], na.rm = TRUE),
air.diff = mean(df$air_temp[df$detection], na.rm = TRUE) - mean(df$air_temp[!df$detection], na.rm = TRUE),
gr.diff = mean(df$gr_temp[df$detection], na.rm = TRUE) - mean(df$gr_temp[!df$detection], na.rm = TRUE),
wind.diff = mean(df$avg_wind_spd[df$detection], na.rm = TRUE) - mean(df$avg_wind_spd[!df$detection], na.rm = TRUE),
vpd.diff = mean(df$vpd[df$detection], na.rm = TRUE) - mean(df$vpd[!df$detection], na.rm = TRUE))
}

boot.results <- boot.resamples %>%
mutate(estimates = map(splits, covariate.diffs)) %>%
unnest(estimates)
```

## Bootstrap Results Summary
```{r bs confidence tbl}
boot.confin_tbl <- boot.results %>%
  summarise(
    rock.min = quantile(rock.diff, 0.025, na.rm = TRUE),
    rock.med = quantile(rock.diff, 0.50, na.rm = TRUE),
    rock.max = quantile(rock.diff, 0.975, na.rm = TRUE),
    
    air.min = quantile(air.diff, 0.025, na.rm = TRUE),
    air.med = quantile(air.diff, 0.50, na.rm = TRUE),
    air.max = quantile(air.diff, 0.975, na.rm = TRUE),
    
    gr.min = quantile(gr.diff, 0.025, na.rm = TRUE),
    gr.med = quantile(gr.diff, 0.50, na.rm = TRUE),
    gr.max = quantile(gr.diff, 0.975, na.rm = TRUE),
    
    wind.min = quantile(wind.diff, 0.025, na.rm = TRUE),
    wind.med = quantile(wind.diff, 0.50, na.rm = TRUE),
    wind.max = quantile(wind.diff, 0.975, na.rm = TRUE),
    
    vpd.min = quantile(vpd.diff, 0.025, na.rm = TRUE),
    vpd.med = quantile(vpd.diff, 0.50,  na.rm = TRUE),
    vpd.max = quantile(vpd.diff, 0.975, na.rm = TRUE))

# reformat table 
boot.confin_tbl<- tibble(
  variable = c("rock_ind", "air_temp", "gr_temp", "avg_wind_spd", "vpd"),
  lcl = c(boot.confin_tbl$rock.min, boot.confin_tbl$air.min, boot.confin_tbl$gr.min, boot.confin_tbl$wind.min, boot.confin_tbl$vpd.min),
  med = c(boot.confin_tbl$rock.med, boot.confin_tbl$air.med, boot.confin_tbl$gr.med, boot.confin_tbl$wind.med, boot.confin_tbl$vpd.med),
  ucl = c(boot.confin_tbl$rock.max, boot.confin_tbl$air.max, boot.confin_tbl$gr.max, boot.confin_tbl$wind.max, boot.confin_tbl$vpd.max))

# calculate two-sided p-value for each variable
boot.pvals <- boot.results %>%
  summarise(
    rock.p = 2 * min(mean(rock.diff <= 0, na.rm = TRUE), mean(rock.diff >= 0, na.rm = TRUE)),
    air.p  = 2 * min(mean(air.diff <= 0, na.rm = TRUE), mean(air.diff >= 0, na.rm = TRUE)),
    gr.p   = 2 * min(mean(gr.diff <= 0, na.rm = TRUE), mean(gr.diff >= 0, na.rm = TRUE)),
    wind.p = 2 * min(mean(wind.diff <= 0, na.rm = TRUE), mean(wind.diff >= 0, na.rm = TRUE)),
    vpd.p  = 2 * min(mean(vpd.diff <= 0, na.rm = TRUE), mean(vpd.diff >= 0, na.rm = TRUE)))

# create summary table with CI tbl & p-values
boot.summary_tbl <- boot.confin_tbl %>%
  left_join(tibble(variable = c("rock_ind", "air_temp", "gr_temp", "avg_wind_spd", "vpd"),
      p_value = as.numeric(boot.pvals[1, ])),
    by = "variable")

boot.summary_tbl
```

The bootstrap analysis indicates that detections occurred under a higher rockiness index value (sandier substrates), higher air temperature, lower wind speed, and higher vapor pressure deficit compared to non-detections. Ground temperature differences were small, with confidence intervals overlapping zero, indicating weak and inconsistent differences between detection and non-detection observations. Overall, the bootstrap results support rockiness, air temperature, wind speed, and vapor pressure deficit as covariates that differ consistently between detection and non-detection observations, while ground temperature shows weak evidence.

In the following sections histograms of results and box plots of raw data help to visualize these results.

## Bootstrap Distributions

```{r bs histograms}
# function to plot bootstrap results
plot.hist <- function(df, colname, xlab) {
  ggplot(df, aes(x = .data[[colname]])) +
    geom_histogram(bins = 30, fill = "tan", color = "black") +
    geom_vline(xintercept = 0, linetype = "dashed") +
    labs(
      title = paste("Bootstrap distribution:", xlab),
      x = paste0("Difference in mean ", xlab, " (detection vs non-detection)"),
      y = "Bootstrap Frequency") +
    theme_classic()
}

plot.hist(boot.results, "rock.diff", "Rockiness")
plot.hist(boot.results, "air.diff", "Air Temperature")
plot.hist(boot.results, "gr.diff", "Ground Temperature")
plot.hist(boot.results, "wind.diff", "Average Wind Speed")
plot.hist(boot.results, "vpd.diff", "Vapor Pressure Deficit")
```

## Bootstrap Boxplots
```{r bs raw data boxplots}
# function to plot raw data
plot.box <- function(df, colname, xlab) {
  
  ggplot(df, aes(x = factor(detection), y = .data[[colname]])) +
    geom_boxplot(fill= c("grey80", "tan")) +
    labs(
      title = paste(xlab, "differences at detection vs non-detection points"),
      x = "Detection",
      y = xlab) +
    theme_classic()
}

plot.box(transects, "rock_ind", "Rockiness")
plot.box(transects, "air_temp", "Air Temperature")
plot.box(transects, "gr_temp", "Ground Temperature")
plot.box(transects, "avg_wind_spd", "Average Wind Speed")
plot.box(transects, "vpd", "Vapor Pressure Deficit")
```


# Re-run Detection Selection

After completing the bootstrap analysis I expanded the detection candidate set to include air temperature (with its quadratic term) alone and in combination with rock and wind. The goal of this process was to test whether air temperature explains any additional detection variation. This section contains updated model selection results which were used to select the final detection formula for best-fit model comparison.

Added Candidate Models: </br>
 - dm8: ~ t_air + I(t_air^2) </br>
 - dm9: ~ wind + t_air + I(t_air^2) </br>
 - dm10: ~ rock + t_air + I(t_air^2) </br>
 - dm11: ~ rock + wind + t_air + I(t_air^2) </br>
 

```{r adding air temp det models}
dm8 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ t_air + I(t_air^2),
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits,
             n.samples = n.samples,
             priors = gm.priors,
             n.omp.threads = 1,
             verbose = FALSE,
             n.report = 2000,
             n.burn = n.burn,
             n.thin = n.thin,
             n.chains = n.chains)

dm9 <- PGOcc(occ.formula = fit.occupancy.formula,
             det.formula = ~ wind + t_air + I(t_air^2),
             data = list(
               y = y,
               occ.covs = occ.cov_df,
               det.covs = det.cov_list),
             inits = gm.inits,
             n.samples = n.samples,
             priors = gm.priors,
             n.omp.threads = 1,
             verbose = FALSE,
             n.report = 2000,
             n.burn = n.burn,
             n.thin = n.thin,
             n.chains = n.chains)

dm10 <- PGOcc(occ.formula = fit.occupancy.formula,
              det.formula = ~ rock + t_air + I(t_air^2),
              data = list(
                y = y,
                occ.covs = occ.cov_df,
                det.covs = det.cov_list),
              inits = gm.inits,
              n.samples = n.samples,
              priors = gm.priors,
              n.omp.threads = 1,
              verbose = FALSE,
              n.report = 2000,
              n.burn = n.burn,
              n.thin = n.thin,
              n.chains = n.chains)

dm11 <- PGOcc(occ.formula = fit.occupancy.formula,
              det.formula = ~ rock + wind + t_air + I(t_air^2),
              data = list(
                y = y,
                occ.covs = occ.cov_df,
                det.covs = det.cov_list),
              inits = gm.inits,
              n.samples = n.samples,
              priors = gm.priors,
              n.omp.threads = 1,
              verbose = FALSE,
              n.report = 2000,
              n.burn = n.burn,
              n.thin = n.thin,
              n.chains = n.chains)
```

## WAIC Table
```{r updated detection WAIC tbl}
dm1.waic <- waicOcc(dm1)
dm2.waic <- waicOcc(dm2)
dm3.waic <- waicOcc(dm3)
dm4.waic <- waicOcc(dm4)
dm5.waic <- waicOcc(dm5)
dm6.waic <- waicOcc(dm6)
dm7.waic <- waicOcc(dm7)
dm8.waic  <- waicOcc(dm8)
dm9.waic  <- waicOcc(dm9)
dm10.waic <- waicOcc(dm10)
dm11.waic <- waicOcc(dm11)

dm1.df <- data.frame(model = "dm1", t(dm1.waic))
dm2.df <- data.frame(model = "dm2", t(dm2.waic))
dm3.df <- data.frame(model = "dm3", t(dm3.waic))
dm4.df <- data.frame(model = "dm4", t(dm4.waic))
dm5.df <- data.frame(model = "dm5", t(dm5.waic))
dm6.df <- data.frame(model = "dm6", t(dm6.waic))
dm7.df <- data.frame(model = "dm7", t(dm7.waic))
dm8.df  <- data.frame(model = "dm8",  t(dm8.waic))
dm9.df  <- data.frame(model = "dm9",  t(dm9.waic))
dm10.df <- data.frame(model = "dm10", t(dm10.waic))
dm11.df <- data.frame(model = "dm11", t(dm11.waic))

dm.waic_df <- bind_rows(list(dm1.df, dm2.df, dm3.df, dm4.df, dm5.df, dm6.df, dm7.df, dm8.df, dm9.df, dm10.df, dm11.df))

dm.waic_tbl <- 
  dm.waic_df %>%
  mutate(
    elpd = as.numeric(elpd),
    pD = as.numeric(pD),
    WAIC = as.numeric(WAIC)) %>%
  mutate(
    delta = WAIC - min(WAIC),
    weight = exp(-0.5 * delta)/ sum (exp(-0.5 * delta))) %>%
  arrange(WAIC)

dm.waic_tbl
```

This updated model selection indicates the strongest support for models incorporating wind, rockiness, and air temperature effects. The top-ranked model (dm9) has the highest model weight, however the second-ranked model (dm11) is very similiar. Models excluding air temperature are consistently ranked lower, which shows overall improved model performance when air temperature was included.

## Variable Importance 
```{r updated detection variable importance}
# model weights as objects
dm1.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm1"]
dm2.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm2"]
dm3.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm3"]
dm4.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm4"]
dm5.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm5"]
dm6.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm6"]
dm7.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm7"]
dm8.weight  <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm8"]
dm9.weight  <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm9"]
dm10.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm10"]
dm11.weight <- dm.waic_tbl$weight[dm.waic_tbl$model == "dm11"]

rock.sum_weight <- dm2.weight + dm4.weight + dm5.weight + dm7.weight + dm10.weight + dm11.weight
t_gr.sum_weight <- dm3.weight + dm5.weight + dm6.weight + dm7.weight
wind.sum_weight <- dm4.weight + dm6.weight + dm7.weight + dm9.weight + dm11.weight
t_air.sum_weight <- dm8.weight + dm9.weight + dm10.weight + dm11.weight

dm.var.importance <- data.frame(
  variable = c("rock","t_gr", "wind", "t_air"),
  sum_weight = c(rock.sum_weight, t_gr.sum_weight,wind.sum_weight,t_air.sum_weight))

dm.var.importance
```

Updated variable importance results show wind and air temperature were included in nearly all top-supported models, suggesting consistent support for both as predictors of detectability. Rockiness maintained moderate support but was less consistently selected after adding air temperature than when air temperature was excluded. Ground temperature shows the weakest support.

## Model-averaged Coefficients
```{r updated detection model averaged coefficients}
# dm1 posterior means
dm1.mat <- as.matrix(dm1$alpha.samples)
dm1.means <- colMeans(dm1.mat)

dm1_int   <- dm1.means["(Intercept)"]
dm1_rock  <- 0
dm1_tgr   <- 0
dm1_tgr2  <- 0
dm1_wind  <- 0
dm1_tair <- 0
dm1_tair2 <- 0

# dm2 posterior means
dm2.mat <- as.matrix(dm2$alpha.samples)
dm2.means <- colMeans(dm2.mat)

dm2_int  <- dm2.means["(Intercept)"]
dm2_rock <- dm2.means["rock"]
dm2_tgr  <- 0
dm2_tgr2 <- 0
dm2_wind <- 0
dm2_tair <- 0
dm2_tair2 <- 0

# dm3 posterior means
dm3.mat <- as.matrix(dm3$alpha.samples)
dm3.means <- colMeans(dm3.mat)

dm3_int  <- dm3.means["(Intercept)"]
dm3_rock <- 0
dm3_tgr  <- dm3.means["t_gr"]
dm3_tgr2 <- dm3.means["I(t_gr^2)"]
dm3_wind <- 0
dm3_tair <- 0
dm3_tair2 <- 0

# dm4 posterior means
dm4.mat <- as.matrix(dm4$alpha.samples)
dm4.means <- colMeans(dm4.mat)

dm4_int  <- dm4.means["(Intercept)"]
dm4_rock <- dm4.means["rock"]
dm4_tgr  <- 0
dm4_tgr2 <- 0
dm4_wind <- dm4.means["wind"]
dm4_tair <- 0
dm4_tair2 <- 0

# dm5 posterior means
dm5.mat <- as.matrix(dm5$alpha.samples)
dm5.means <- colMeans(dm5.mat)

dm5_int  <- dm5.means["(Intercept)"]
dm5_rock <- dm5.means["rock"]
dm5_tgr  <- dm5.means["t_gr"]
dm5_tgr2 <- dm5.means["I(t_gr^2)"]
dm5_wind <- 0
dm5_tair <- 0
dm5_tair2 <- 0

# dm6 posterior means
dm6.mat <- as.matrix(dm6$alpha.samples)
dm6.means <- colMeans(dm6.mat)

dm6_int  <- dm6.means["(Intercept)"]
dm6_rock <- 0
dm6_tgr  <- dm6.means["t_gr"]
dm6_tgr2 <- dm6.means["I(t_gr^2)"]
dm6_wind <- dm6.means["wind"]
dm6_tair <- 0
dm6_tair2 <- 0

# dm7 posterior means
dm7.mat <- as.matrix(dm7$alpha.samples)
dm7.means <- colMeans(dm7.mat)

dm7_int  <- dm7.means["(Intercept)"]
dm7_rock <- dm7.means["rock"]
dm7_tgr  <- dm7.means["t_gr"]
dm7_tgr2 <- dm7.means["I(t_gr^2)"]
dm7_wind <- dm7.means["wind"]
dm7_tair <- 0
dm7_tair2 <- 0

# dm8 posterior means (air temp)
dm8.mat <- as.matrix(dm8$alpha.samples)
dm8.means <- colMeans(dm8.mat)

dm8_int   <- dm8.means["(Intercept)"]
dm8_rock  <- 0
dm8_tgr   <- 0
dm8_tgr2  <- 0
dm8_wind  <- 0
dm8_tair  <- dm8.means["t_air"]
dm8_tair2 <- dm8.means["I(t_air^2)"]

# dm9 posterior means (wind + air)
dm9.mat <- as.matrix(dm9$alpha.samples)
dm9.means <- colMeans(dm9.mat)

dm9_int   <- dm9.means["(Intercept)"]
dm9_rock  <- 0
dm9_tgr   <- 0
dm9_tgr2  <- 0
dm9_wind  <- dm9.means["wind"]
dm9_tair  <- dm9.means["t_air"]
dm9_tair2 <- dm9.means["I(t_air^2)"]

# dm10 posterior means (rock + air)
dm10.mat <- as.matrix(dm10$alpha.samples)
dm10.means <- colMeans(dm10.mat)

dm10_int   <- dm10.means["(Intercept)"]
dm10_rock  <- dm10.means["rock"]
dm10_tgr   <- 0
dm10_tgr2  <- 0
dm10_wind  <- 0
dm10_tair  <- dm10.means["t_air"]
dm10_tair2 <- dm10.means["I(t_air^2)"]

# dm11 posterior means (rock + wind + air)
dm11.mat <- as.matrix(dm11$alpha.samples)
dm11.means <- colMeans(dm11.mat)

dm11_int   <- dm11.means["(Intercept)"]
dm11_rock  <- dm11.means["rock"]
dm11_tgr   <- 0
dm11_tgr2  <- 0
dm11_wind  <- dm11.means["wind"]
dm11_tair  <- dm11.means["t_air"]
dm11_tair2 <- dm11.means["I(t_air^2)"]

# multiply each coefficient by its model’s weight and sum across models
dm.avg_int <-
  (dm1_int * dm1.weight) + (dm2_int * dm2.weight) + 
  (dm3_int * dm3.weight) + (dm4_int * dm4.weight) + 
  (dm5_int * dm5.weight) + (dm6_int * dm6.weight) + 
  (dm7_int * dm7.weight) + (dm8_int * dm8.weight) +
  (dm9_int * dm9.weight) + (dm10_int * dm10.weight) +
  (dm11_int * dm11.weight)


dm.avg_rock <-
  (dm1_rock * dm1.weight) + (dm2_rock * dm2.weight) + 
  (dm3_rock * dm3.weight) + (dm4_rock * dm4.weight) + 
  (dm5_rock * dm5.weight) + (dm6_rock * dm6.weight) + 
  (dm7_rock * dm7.weight) + (dm8_rock * dm8.weight) +
  (dm9_rock * dm9.weight) + (dm10_rock * dm10.weight) +
  (dm11_rock * dm11.weight)

dm.avg_tgr <-
  (dm1_tgr * dm1.weight) + (dm2_tgr * dm2.weight) + 
  (dm3_tgr * dm3.weight) + (dm4_tgr * dm4.weight) + 
  (dm5_tgr * dm5.weight) + (dm6_tgr * dm6.weight) + 
  (dm7_tgr * dm7.weight) + (dm8_tgr * dm8.weight) +
  (dm9_tgr * dm9.weight) + (dm10_tgr * dm10.weight) +
  (dm11_tgr * dm11.weight)

dm.avg_tgr2 <-
  (dm1_tgr2 * dm1.weight) + (dm2_tgr2 * dm2.weight) + 
  (dm3_tgr2 * dm3.weight) + (dm4_tgr2 * dm4.weight) + 
  (dm5_tgr2 * dm5.weight) + (dm6_tgr2 * dm6.weight) + 
  (dm7_tgr2 * dm7.weight) + (dm8_tgr2 * dm8.weight) +
  (dm9_tgr2 * dm9.weight) + (dm10_tgr2 * dm10.weight) +
  (dm11_tgr2 * dm11.weight)

dm.avg_wind <-
  (dm1_wind * dm1.weight) + (dm2_wind * dm2.weight) + 
  (dm3_wind * dm3.weight) + (dm4_wind * dm4.weight) + 
  (dm5_wind * dm5.weight) + (dm6_wind * dm6.weight) + 
  (dm7_wind * dm7.weight) + (dm8_wind * dm8.weight) +
  (dm9_wind * dm9.weight) + (dm10_wind * dm10.weight) +
  (dm11_wind * dm11.weight)


dm.avg_tair <-
  (dm1_tair * dm1.weight) + (dm2_tair * dm2.weight) + 
  (dm3_tair * dm3.weight) + (dm4_tair * dm4.weight) + 
  (dm5_tair * dm5.weight) + (dm6_tair * dm6.weight) + 
  (dm7_tair * dm7.weight) + (dm8_tair * dm8.weight) +
  (dm9_tair * dm9.weight) + (dm10_tair * dm10.weight) +
  (dm11_tair * dm11.weight)

dm.avg_tair2 <-
  (dm1_tair2 * dm1.weight) + (dm2_tair2 * dm2.weight) + 
  (dm3_tair2 * dm3.weight) + (dm4_tair2 * dm4.weight) + 
  (dm5_tair2 * dm5.weight) + (dm6_tair2 * dm6.weight) + 
  (dm7_tair2 * dm7.weight) + (dm8_tair2 * dm8.weight) +
  (dm9_tair2 * dm9.weight) + (dm10_tair2 * dm10.weight) +
  (dm11_tair2 * dm11.weight)

# final data frame
dm.modavg <- data.frame(
  avg_coefficients = c(dm.avg_int, dm.avg_rock, dm.avg_tair, dm.avg_tair2, dm.avg_tgr, dm.avg_tgr2, dm.avg_wind))

dm.modavg
```

Model-averaged coefficients for wind, rockiness, and ground temperature are similar to the previous model-selection results. However, With the addition of air temperature, air temperature exhibits a positive linear effect with a negative quadratic term, which suggests that detection probability increases with air temperature but shows a bell-shaped response to increasing air temperature.

## Best-fit Detection Formulas

Based on WAIC model selection, bootstrap mean-difference comparisons, and model-averaged variable importance, rockiness, wind speed, and air temperature (including a quadratic air temperature term) consistently show strong support as predictors of detection probability; therefore, I selected the final detection formula (~ rock + wind + t_air + I(t_air^2)).

```{r tested best-fit detection formulas}
fit.detection.formula <- ~ rock + wind + t_air + I(t_air^2)
```

# Best-fit Model

In this section final occupancy and detection formulas are combined to fit a best-supported occupancy model. Model performance is evaluated relative to global and null occupancy models using WAIC and k-fold cross-validation, and model fit is assessed using Freeman–Tukey and chi-squared posterior predictive checks.

```{r best-fit model selection}
best.fit_model <- PGOcc(occ.formula = fit.occupancy.formula,
                        det.formula = fit.detection.formula, 
                        data = list(
                          y = y,
                          occ.covs = occ.cov_df,
                          det.covs = det.cov_list),
                        inits = gm.inits, 
                        n.samples = n.samples, 
                        priors = gm.priors, 
                        n.omp.threads = 1, 
                        verbose = FALSE, 
                        n.report = 2000, 
                        n.burn = n.burn, 
                        n.thin = n.thin, 
                        n.chains = n.chains)


null_model <- PGOcc(occ.formula = ~ 1,
                    det.formula = fit.detection.formula, 
                    data = list(
                      y = y,
                      occ.covs = occ.cov_df,
                      det.covs = det.cov_list),
                    inits = gm.inits, 
                    n.samples = n.samples, 
                    priors = gm.priors, 
                    n.omp.threads = 1, 
                    verbose = FALSE, 
                    n.report = 2000, 
                    n.burn = n.burn, 
                    n.thin = n.thin, 
                    n.chains = n.chains)

```

## Best-fit WAIC Table
```{r best-fit waic table}
global.waic <- waicOcc(global_model)
best.fit.waic <- waicOcc(best.fit_model)
null.waic <- waicOcc(null_model)

global.waic_df <- data.frame(model = "global_model", t(global.waic))
best.fit.waic_df<- data.frame(model = "best.fit_model", t(best.fit.waic))
null.waic_df <- data.frame(model = "null_model", t(null.waic))

models.waic_df <- bind_rows(list(global.waic_df, best.fit.waic_df, null.waic_df))

models.waic_tbl <- 
  models.waic_df %>%
  mutate(
    elpd = as.numeric(elpd),
    pD = as.numeric(pD),
    WAIC = as.numeric(WAIC)) %>%
  mutate(
    delta = WAIC - min(WAIC),
    weight = exp(-0.5 * delta)/ sum (exp(-0.5 * delta))) %>%
  arrange(WAIC)

models.waic_tbl
```

Comparing WAIC among the global, best-fit, and null models shows the global model with the lowest WAIC. However, the global model includes multiple highly collinear detection covariates (air temperature, vapor pressure deficit, and ground temperature), increasing the risk of overparameterization and reducing interpretability of individual effects. 

To prioritize parsimony and biological inference, I have chosen the reduced detection model including wind, rockiness, and air temperature (with a quadratic term). This model performs well relative to the null model and avoids multicollinearity among detection predictors.

## Best-fit K-fold Cross-validation
```{r best fit kfold}
global_cv  <- PGOcc(occ.formula = global.occ.formula,
                    det.formula = global.det.formula, 
                    data = list(
                      y = y,
                      occ.covs = occ.cov_df,
                      det.covs = det.cov_list),
                    inits = gm.inits, 
                    n.samples = n.samples, 
                    priors = gm.priors, 
                    n.omp.threads = 1, 
                    verbose = FALSE, 
                    n.report = 2000, 
                    n.burn = n.burn, 
                    n.thin = n.thin, 
                    n.chains = n.chains,
                    k.fold = 3,
                    k.fold.threads = 3)

best.fit_cv  <- PGOcc(occ.formula = fit.occupancy.formula,
                      det.formula = fit.detection.formula, 
                      data = list(
                        y = y,
                        occ.covs = occ.cov_df,
                        det.covs = det.cov_list),
                      inits = gm.inits, 
                      n.samples = n.samples, 
                      priors = gm.priors, 
                      n.omp.threads = 1, 
                      verbose = FALSE, 
                      n.report = 2000, 
                      n.burn = n.burn, 
                      n.thin = n.thin, 
                      n.chains = n.chains,
                      k.fold = 3,
                      k.fold.threads = 3)


null_cv <- PGOcc(occ.formula = ~1,
                  det.formula = fit.detection.formula, 
                  data = list(
                    y = y,
                    occ.covs = occ.cov_df,
                    det.covs = det.cov_list),
                  inits = gm.inits, 
                  n.samples = n.samples, 
                  priors = gm.priors, 
                  n.omp.threads = 1, 
                  verbose = FALSE, 
                  n.report = 2000, 
                  n.burn = n.burn, 
                  n.thin = n.thin, 
                  n.chains = n.chains,
                  k.fold = 3,
                  k.fold.threads = 3)

global.kfold.dev <- global_cv$k.fold.deviance
best.fit.kfold.dev <- best.fit_cv$k.fold.deviance
null.kfold.dev <- null_cv$k.fold.deviance


kfold.dev_tbl <- data.frame(
  global = global.kfold.dev,
  best = best.fit.kfold.dev,
  null = null.kfold.dev)

kfold.dev_tbl
```

K-fold cross-validation further supports selection of the reduced best-fit model. The best-fit model shows the lowest k-fold deviance, indicating better out-of-sample predictive performance relative to both the global model and the null model. These results show that although the global model results in higher WAIC support, the reduced model provides a more parsimonious/improved performance.

## Model Summary

After comparing WAIC, k-fold cross-validation deviance, and taking into account predictor variable collinearity, the final best fit model can now be used to estimate covariate effects and generate posterior predictions.

```{r final best fit model}
fit.detection.formula <- ~ rock + wind + t_air + I(t_air^2)
best.fit_model<- PGOcc(occ.formula = fit.occupancy.formula,
                          det.formula = fit.detection.formula, 
                          data = list(
                            y = y,
                            occ.covs = occ.cov_df,
                            det.covs = det.cov_list),
                          inits = gm.inits, 
                          n.samples = n.samples, 
                          priors = gm.priors, 
                          n.omp.threads = 1, 
                          verbose = FALSE, 
                          n.report = 2000, 
                          n.burn = n.burn, 
                          n.thin = n.thin, 
                          n.chains = n.chains)
summary(best.fit_model)
```

The final best-fit occupancy model converged well (Rhat values < 1.1; effective sample sizes > 600). For occupancy, shrub density exhibits a positive effect and rockiness exhibits a negative effect, though credible intervals for both covariates overlap zero. For the detection process, wind speed shows a negative effect and the rockiness shows a positive effect (higher rockiness index values = sandier substrates), consistent with track-based detections being less persistent under windier conditions and more detectable on substrates that retain tracks. Air temperature shows a positive linear effect with a negative quadratic term, indicating detectability increased with air temperature but plateaues at higher values.

```{r predicted occ and detection prob}
pred.occupancy <- plogis(best.fit_model$beta.samples[, "(Intercept)"])
pred.detection   <- plogis(best.fit_model$alpha.samples[, "(Intercept)"])

quantile(pred.occupancy, c(0.025, 0.5, 0.975))

quantile(pred.detection,   c(0.025, 0.5, 0.975))
```

Additionally, from the model summary we can calculate predicted occupancy and detection probability across the study area under mean site conditions. The final model predicts probability of site occupancy at 83% and detection probability during a survey 2.7%. These results indicate that sites were likely occupied across the study area, but that individual surveys had a low probability of detecting the species even when present.

## Freeman-Tukey Test
```{r best fit freeman test sites}
fit.site_ppc <- ppcOcc(best.fit_model, fit.stat = 'freeman-tukey', group = 1)
fit.rep_ppc <- ppcOcc(best.fit_model, fit.stat = 'freeman-tukey', group = 2)

summary(fit.rep_ppc)
summary(fit.site_ppc) 
```

Bayesian p-values for the site and replicate data using the Freeman-Tukey test fall within acceptable ranges indicating no lack of fit, the following plots aid in visualizing the replicate data set vs the actual dataset.

```{r best fit freeman test reps}
# create df of group 1 (site); color for actual data set
fit.site.ppc_df <- data.frame(fit = fit.site_ppc$fit.y, 
                              fit.rep = fit.site_ppc$fit.y.rep, 
                              color = 'lightskyblue1')
# set color for fit data
fit.site.ppc_df$color[fit.site.ppc_df$fit.rep > fit.site.ppc_df$fit] <- 'lightsalmon'

# plot
plot(fit.site.ppc_df$fit, fit.site.ppc_df$fit.rep, bg = fit.site.ppc_df$color, pch = 21, 
     ylab = 'Fit', xlab = 'True') 
lines(fit.site.ppc_df$fit, fit.site.ppc_df$fit, col = 'black')

# create df of group 2 (replicates); color for actual data set
fit.rep.ppc_df <- data.frame(fit = fit.rep_ppc$fit.y, 
                             fit.rep = fit.rep_ppc$fit.y.rep, 
                             color = 'lightskyblue1')
# set color for fit data
fit.rep.ppc_df$color[fit.rep.ppc_df$fit.rep > fit.rep.ppc_df$fit] <- 'lightsalmon'

# plot
plot(fit.rep.ppc_df$fit, fit.rep.ppc_df$fit.rep, bg = fit.rep.ppc_df$color, pch = 21, 
     ylab = 'Fit', xlab = 'True') 
lines(fit.rep.ppc_df$fit, fit.rep.ppc_df$fit, col = 'black')
```


## Chi-Squared Test 
```{r chi squared test best fit}
fit.site_chi <- ppcOcc(best.fit_model, fit.stat = "chi-squared", group = 1) # site
fit.rep_chi <- ppcOcc(best.fit_model, fit.stat = "chi-squared", group = 2) # replicate

summary(fit.site_chi)
summary(fit.rep_chi)
```

Bayesian p-values for the site and replicate data using the Chi-squared test fall within acceptable ranges indicating no lack of fit.

# Habitat Class Comparison

Sites were apriori selected based on a habitat quality index: low, medium, and high. Habitat quality was established based on site topography, native plant diversity and abundance, habitat patch size, fire history, proximity to urban development, and Gila monster sighting records from 1900 - 2024. To explore differences in occupancy among habitat classes, this section retains the final detection model and occupancy is reparameterized as a categorical habitat effect. Posterior predictions are then converted to occupancy probabilities and credible intervals for each habitat class. Additionally, posterior probabilities are compared to quantify the strength of evidence that occupancy differs among habitat classes.

```{r habitat class libraries}
library(dplyr)
library(tidyr)
library(readr)
library(janitor)
library(ggplot2)
library(spOccupancy)
```

```{r habitat class set up}
# define habitat classes
high <- c("paradise_canyon", "fort_pearce")
med <- c("sun_river", "cove_wash")
low <- c("white_reef", "turkey_farm")

# ensure site_id columns
occ.cov_df$site_id <- rownames(occ.cov_df)

# assign habitat class based on site_id
occ.cov_df$habitat <- NA_character_

occ.cov_df$habitat[occ.cov_df$site_id %in% low]  <- "low"
occ.cov_df$habitat[occ.cov_df$site_id %in% med]  <- "medium"
occ.cov_df$habitat[occ.cov_df$site_id %in% high] <- "high"

# convert to factor ; set low as the reference level
occ.cov_df$habitat <- factor(
  occ.cov_df$habitat,
  levels = c("low", "medium", "high"))

# ensure habitat classes have 2 sites each
table(occ.cov_df$habitat)

# ensure sites are assigned to correct habitat class
occ.cov_df[, c("site_id", "habitat")]
```

## Habitat Model Summary
```{r habitat class model summary}
# habitat formula
habitat.occ.formula <- ~ habitat

habitat.occ_model <- PGOcc(
  occ.formula = habitat.occ.formula,
  det.formula = fit.detection.formula, 
  data = list(
    y = y,
    occ.covs = occ.cov_df,
    det.covs = det.cov_list),
  inits = gm.inits, 
  n.samples = n.samples, 
  priors = gm.priors, 
  n.omp.threads = 1, 
  verbose = FALSE, 
  n.report = 2000, 
  n.burn = n.burn, 
  n.thin = n.thin, 
  n.chains = n.chains)

summary(habitat.occ_model)
```

The habitat class occupancy model summary shows that the model converged adequately (Rhat < 1.1; effective sample size > 2800), and provides estimates of occupancy differences relative to the low habitat quality class. Medium and high quality classes show higher occupancy probability than the low quality habitat class, however both credible intervals overlap zero, reflecting uncertainty in class-level differences. This result is not unexpected given the small number of sites per class (n = 2) and low detections across the study area. Detection covariate effects are consistent with the final best-fit detection model. 
 
## Probability Table
```{r habitat probability summary table}
prob <- as.matrix(habitat.occ_model$beta.samples)
prob.low <- plogis(prob[, "(Intercept)"])
prob.medium <- plogis(prob[, "(Intercept)"] + prob[, "habitatmedium"])
prob.high <- plogis(prob[, "(Intercept)"] + prob[, "habitathigh"])

# credible interval table
habitat.prob.ci_tbl <- rbind(
  low = quantile(prob.low, c(0.025, 0.5, 0.975)),
  medium = quantile(prob.medium, c(0.025, 0.5, 0.975)),
  high = quantile(prob.high, c(0.025, 0.5, 0.975)))

habitat.prob.ci_tbl
```


The posterior occupancy probability estimates show high overall site use across all habitat classes. Median occupancy probability is the lowest in low-quality habitat and higher in medium and high-quality habitat. Although credible intervals overlap zero across habitat classes, point estimates suggest some increased occupancy probability with habitat quality throughout the study area. 

## Probability Means Plot

The following plot shows the mean predicted occupancy in each habitat class as well as the upper and lower credible intervals. 

```{r habitat class probabilty ggplot}
# create habitat data frame with 3 habitat class levels
habitat_df <- data.frame(
  habitat = factor(c("low", "medium", "high"),
                   levels = c("low", "medium", "high")))

# occupancy matrix; using ~habitat occupancy formula
habitat.mat <- model.matrix(~ habitat, data = habitat_df)

# predict occupancy for each habitat class
habitat.psi_pred <- predict(
  habitat.occ_model,
  X.0  = habitat.mat,
  type = "occupancy")

# get posterior psi (occupancy) samples; cols: habitat levels rows: iterations
habitat.psi_samples <- habitat.psi_pred$psi.0.samples

# name columns
colnames(habitat.psi_samples) <- c("low", "medium", "high")

# compute mean psi (occupancy) and 95% CI for each habitat class
psi_low    <- habitat.psi_samples[, "low"]
psi_medium <- habitat.psi_samples[, "medium"]
psi_high   <- habitat.psi_samples[, "high"]

# summary habitat class psi df
habitat.psi_df <- data.frame(
  class = c("low", "medium", "high"),
  psi_mean = c(mean(psi_low), mean(psi_medium), mean(psi_high)),
  psi_lcl  = c(quantile(psi_low, 0.025),
               quantile(psi_medium, 0.025),
               quantile(psi_high, 0.025)),
  psi_ucl  = c(quantile(psi_low, 0.975),
               quantile(psi_medium, 0.975),
               quantile(psi_high, 0.975)))

# simplify df of habitat classes for plotting
habitat.psi_df <- habitat.psi_df %>%
  select(class, psi_mean, psi_lcl, psi_ucl)

# plot means + upper & lower CI error bars
ggplot(habitat.psi_df, aes(x = class, y = psi_mean)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymin = psi_lcl, ymax = psi_ucl), width = 0.1) +
  labs(
    x = "Habitat Quality",
    y = "Occupancy Probability (ψ)",
    title = "Predicted Occupancy by Habitat Quality") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

## Comparison Table
```{r habitat class comparison table}
# habitat class comparisons
prob.high_v_med <- mean(habitat.psi_samples[, "high"] > habitat.psi_samples[, "medium"])
prob.high_v_low <- mean(habitat.psi_samples[, "high"] > habitat.psi_samples[, "low"])
prob.med_v_low  <- mean(habitat.psi_samples[, "medium"] > habitat.psi_samples[, "low"])

# habitat class comparison table
habitat.comp_tbl <- data.frame(
  comparison = (c("High > Medium", "High > Low", "Medium > Low")),
  probability = (c(prob.high_v_med, prob.high_v_low, prob.med_v_low)))

habitat.comp_tbl
```

From the pairwise comparisons, there is moderate support for higher occupancy in medium and high quality habitats relative to low quality habitat. In contrast there is little to no support for a difference between high and medium quality habitats. 

## Comparison Plot

The following plot visualizes predicted habitat class preference probabilities.

```{r habitat class comparison plot}
ggplot(habitat.comp_tbl, aes(x = probability, y = reorder(comparison, probability))) +
  geom_point(size = 3) +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
  labs(
    x = "Posterior probability",
    y = NULL,
    title = "Habitat Class Preference Probability - Posterior Distributions",
    subtitle = "Dashed line: 0.5 = no preference") +
  theme_bw()
```

# Summary Statement

This analysis applied a hierarchical occupancy modeling framework to quantify both site occupancy and detection processes for Gila monsters in southern Utah while accounting for imperfect detection. 

Model selection, bootstrap inference, and variable-importance analyses identified wind speed, substrate conditions, and air temperature as the primary effetcs on detection probability, and these covariates were incorporated into a Bayesian occupancy model. Occupancy estimates indicated high site use across the study area, with predicted occupancy probabilities exceeding 80% under mean-centered conditions. Habitat-class comparisons suggested modest increases in occupancy in medium and high quality habitats relative to low quality habitats, though differences exhibit significant uncertainty. Detection probability during a survey was low (~2.7%), highlighting the importance of repeated sampling and optimal survey conditions when searching for Gila monsters. These results aim to provide a framework for understanding spatial patterns of Gila monster site occupancy and survey detectability to inform future monitoring and habitat management.
